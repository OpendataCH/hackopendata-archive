{"contributors":[{"path":"","role":"author","title":"loleg"}],"created":"2024-06-05T15:28","description":"The 2020 Edition of the Swiss Open Cultural Data Hackathon will take place on 5-6 June as an ONLINE hackathon. This edition is virtually hosted by the Swiss Institute for Information Science at the FHGR Chur, in collaboration with the Institute for Multimedia Production. The focus of the GLAMhack will lie on Linked Open Data, Machine Learning, Human-Computer-Interaction and Crowdsourcing. Once again, we are happy to collaborate with Wikimedia CH, infoclio.ch and other members of the Friends of OpenGLAM Network.","homepage":"https://make.opendata.ch/wiki/event:2020-06","keywords":["dribdat","hackathon","co-creation"],"licenses":[{"name":"ODC-PDDL-1.0","path":"http://opendatacommons.org/licenses/pddl/","title":"Open Data Commons Public Domain Dedication & License 1.0"}],"name":"event-1","resources":[{"data":[{"aftersubmit":"","boilerplate":"You are welcome to use any platform to document your project - the old make.opendata.ch/wiki or a README on GitHub or any other Website we can link to.\r\n\r\nTo embed a real time editable notebook in your challenge on project:\r\n\r\n1. go to https://md.schoolofdata.ch/ - login, and create a notebook\r\n2. click on the dropdown menu to the top right of the editor and select FREELY\r\n3. copy the URL into the [Project link] here, and check \u2611 Embed this","certificate_path":"","community_embed":"<p>Connect to our community on:\r\n<a href=\"https://forum.opendata.ch/search?q=glam\" target=\"_blank\">forum.opendata.ch</a>\r\n| <a href=\"https://twitter.com/search?q=%23GLAMhack2020%20OR%20%23GLAMhack&src=typed_query&f=live\" target=\"_blank\">twitter</a>\r\n| <a href=\"https://www.facebook.com/openglamch/\" target=\"_blank\">facebook</a>\r\n</p>\r\n\r\n<div class=\"codeofconduct\">All attendees, sponsors, partners, volunteers and staff at our hackathon are required to agree with the <a href=\"https://hackcodeofconduct.org/\" target=\"_blank\">Hack Code of Conduct</a>. Organisers will enforce this code throughout the event. We expect cooperation from all participants to ensure a safe environment for everybody. For more details on how the event is run, see the <a href=\"http://make.opendata.ch/wiki/information:rules\" target=\"_blank\">Guidelines</a> on our wiki.</div>\r\n\r\n<br><p><a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\" target=\"_blank\"><img align=\"left\" style=\"margin-right:1em\" alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a>The contents of this website, unless otherwise stated, are licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\" target=\"_blank\">Creative Commons Attribution 4.0 International License</a>.</p>","community_url":"https://join.slack.com/t/glamhack2020/shared_invite/zt-e8to35c4-gxYgAp2j8EPPl856HeYitw","custom_css":"","description":"The 2020 Edition of the Swiss Open Cultural Data Hackathon will take place on 5-6 June as an ONLINE hackathon. This edition is virtually hosted by the Swiss Institute for Information Science at the FHGR Chur, in collaboration with the Institute for Multimedia Production. The focus of the GLAMhack will lie on Linked Open Data, Machine Learning, Human-Computer-Interaction and Crowdsourcing. Once again, we are happy to collaborate with Wikimedia CH, infoclio.ch and other members of the Friends of OpenGLAM Network.","ends_at":"2020-06-06T18:00","gallery_url":"https://make.opendata.ch/wiki/_media/glam:focus_glamhack2020.png","has_finished":true,"has_started":false,"hashtags":"","hostname":"FHGR Chur","id":1,"instruction":"","location":"Virtual","location_lat":0.0,"location_lon":0.0,"logo_url":"https://glam.opendata.ch/files/2014/05/glam2-200.png","name":"GLAMhack 2020","starts_at":"2020-06-05T09:00","summary":"","webpage_url":"https://make.opendata.ch/wiki/event:2020-06"}],"name":"events"},{"data":[{"autotext":"![header](https://user-images.githubusercontent.com/51910214/83946417-09c46e00-a811-11ea-9b2a-0393189abdd7.jpg)\n\n# 1914 in a Timeline\n 6th Swiss Open Cultural Data Hackathon\n \n## Inhaltsverzeichnis\n\n* [About GLAMhack 2020](#About-GLAMhack-2020)\n* [Project Details](#Project-Details)\n  * [Open Data Information](#Open-Data-Information)\n  * [Concept / Documentation](#Concept--Documentation)\n* [License](#license)\n* [Contact information](#Contact-information)\n\n## About GLAMhack 2020\nThe 2020 Edition of the **Swiss Open Cultural Data Hackathon** will take place on 5-6 June as an ONLINE hackathon. This edition is virtually hosted by the Swiss Institute for Information Science at the FHGR Chur, in collaboration with the Institute for Multimedia Production. The focus of the **GLAMhack** will lie on Linked Open Data, Machine Learning, Human-Computer-Interaction and Crowdsourcing. Once again, we are happy to collaborate with Wikimedia CH, infoclio.ch and other members of the Friends of OpenGLAM Network.\n\nLink to dataset: https://opendata.swiss/de/dataset/journal-de-geneve-gazette-de-lausanne-1914\n\n## Project Details\n### Open Data Information\nThe Historical database of Le Temps comprises 3 newspapers over 200 years. The **Journal de Gen\u00e8ve** ran from 1826 to 1998, the **Gazette de Lausanne** (under different names) from 1798 to 1998, and the **Nouveau Quotidien** from 1991 to 1998, before the merging to the present **Le Temps**. The full archive was digitized and OCRed (extraction of digital text) in 2008. The project is of interest for the community because newspaper databases are becoming a widespread reality across Europe, calling for dedicated techniques to fully exploit them.\n\n### Concept / Documentation\n1914 was an interesting year not only because of the beginning of the First World War. The first cars clattered along unpaved dust roads, the first telephone lines crackled, trams drove through rapidly growing cities: Switzerland from the beginning of 1914 was dynamic and ambitious. But the war brought fear and uncertainty to the neutral country.\n\nIn our project we take a look at Switzerland in 1914, when Switzerland had 3.8 million inhabitants and life expectancy was around 54 years.\n\nIn addition, a rift between German- and French-speaking Swiss also developed during this period. After Germany's invasion of Belgium, many Belgians fled to France, from where they wanted to reach French-speaking Switzerland. Swiss who wanted to take in such refugees were asked to register with a private organization in Lausanne. Within a few weeks, hundreds of applications were received there. This hospitality caused frowning in German-speaking Switzerland.\n\nThis was the beginning of a rift called the \"R\u00f6stigraben\" which still runs along the language border today.\n\nOn Opendata.swiss we found the data of two French-speaking Swiss newspapers from 1914. The data include articles of the year 1914 of the newspapers \"Gazette de Lausanne\" and \"Tribune de Gen\u00e8ve\". Our plan was to translate as many articles as possible into German using the Google Cloud Translation or the DeepL API. After some conception-work we decided not to use these APIs because we didn't need them. We wanted to focus only on a few articles of special events which can be translated manually. We thought it would be better only to publish relevant\n\nThe translated articles are being published on a website and are being enriched with similar articles from nowadays.\n\n## License\nDistributed under the MIT license. For more information, see 'LICENSE'.\n\n## Contact information\nSandro Anderes - https://sandroanderes.ch - hi@sandroanderes.ch<br>\nFrank Zinsli - https://frankzinsli.ch - frank.zinsli@gmail.com<br>\nBernhard Aebersold - https://bernhardaebersold.ch - beni.aebersold@gmail.com<br>\nDavid Indiumi\n\nProjekt link: https://glamhack2020.sandroanderes.ch/\n","autotext_url":"https://github.com/sandroanderes/GLAMhack2020","category_id":"","category_name":"","contact_url":"Slack channel","created_at":"2020-06-04T19:58","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"1914 was an interesting year not only because of the beginning of the First World War. The first cars clattered along unpaved dust roads, the first telephone lines crackled, trams drove through rapidly growing cities: Switzerland from the beginning of 1914 was dynamic and ambitious. But the war brought fear and uncertainty to the neutral country.\r\n\r\nIn our project we take a look at Switzerland in 1914, when Switzerland had 3.8 million inhabitants and life expectancy was around 54 years.\r\n\r\nIn ad...","hashtag":"","id":14,"ident":null,"image_url":"https://avatars1.githubusercontent.com/u/51910214?v=4","is_challenge":false,"is_webembed":true,"logo_color":"#cc9999","logo_icon":"","longtext":"1914 was an interesting year not only because of the beginning of the First World War. The first cars clattered along unpaved dust roads, the first telephone lines crackled, trams drove through rapidly growing cities: Switzerland from the beginning of 1914 was dynamic and ambitious. But the war brought fear and uncertainty to the neutral country.\r\n\r\nIn our project we take a look at Switzerland in 1914, when Switzerland had 3.8 million inhabitants and life expectancy was around 54 years.\r\n\r\nIn addition, a rift between German- and French-speaking Swiss also developed during this period. After Germany's invasion of Belgium, many Belgians fled to France, from where they wanted to reach French-speaking Switzerland. Swiss who wanted to take in such refugees were asked to register with a private organization in Lausanne. Within a few weeks, hundreds of applications were received there.\r\nThis hospitality caused frowning in German-speaking Switzerland.\r\n\r\nThis was the beginning of a rift called the \"R\u00f6stigraben\" which still runs along the language border today.\r\n\r\nOn Opendata.swiss we found the data of two French-speaking Swiss newspapers from 1914. The data include articles of the year 1914 of the newspapers \"Gazette de Lausanne\" and \"Tribune de Gen\u00e8ve\". \r\nOur plan was to translate as many articles as possible into German using the Google Cloud Translation or the DeepL API. After some conception-work we decided not to use these APIs because we didn't need them. We wanted to focus only on a few articles of special events which can be translated manually. We thought it would be better only to publish relevant \r\n\r\nThe translated articles are being published on a website and are being enriched with similar articles from nowadays.\r\n \r\nLink to the data: https://opendata.swiss/en/dataset/journal-de-geneve-gazette-de-lausanne-1914\r\nLink to the prototype: https://glamhack2020.sandroanderes.ch/\r\n\r\n![](https://www.journal21.ch/media/term/4/16765)","maintainer":"bernie","name":"1914 in a Timeline","phase":"Prototype","progress":30,"score":95,"source_url":"https://github.com/sandroanderes/GLAMhack2020","stats":{"commits":0,"during":5,"people":4,"sizepitch":1961,"sizetotal":5931,"total":26,"updates":21},"summary":"In this project, we are translating articles of two french-speaking newspapers from Switzerland from 1914 into German. ","team":"bernie, indumid, sanderes, Frankie1996","team_count":4,"updated_at":"2020-08-26T15:30","url":"https://hack.glam.opendata.ch/project/14","webpage_url":"https://glamhack2020.sandroanderes.ch/"},{"autotext":"","autotext_url":"https://opendata.swiss/en/dataset/nachnamen-pro-plz","category_id":"","category_name":"","contact_url":"https://www.fhgr.ch/en/degree-programmes/bachelors-degree-programmes/media-technology-and-it/multimedia-production/","created_at":"2020-06-05T15:48","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"As we work for two days on this challenge, we've decided to determine, thanks to an open data set, the five most popular family names for the female and male population in 26 cities, in 26 cantons, in Switzerland.\r\n\r\nWe want to visualize this data on an interactive map which shows what family names are predominantly represented throughout the country. \r\n\r\nWe want to visualize this data on an interactive map which shows what family names are predominantly represented throughout the country.\r\nAn e...","hashtag":"","id":17,"ident":null,"image_url":"http://portfolios.htwchur.ch/mmp19/lau/wp-content/uploads/sites/57/2020/06/Website_The_Names_Map_2-1568x919.jpg","is_challenge":false,"is_webembed":true,"logo_color":"","logo_icon":"","longtext":"As we work for two days on this challenge, we've decided to determine, thanks to an open data set, the five most popular family names for the female and male population in 26 cities, in 26 cantons, in Switzerland.\r\n\r\nWe want to visualize this data on an interactive map which shows what family names are predominantly represented throughout the country. \r\n\r\nWe want to visualize this data on an interactive map which shows what family names are predominantly represented throughout the country.\r\nAn example is to find here: https://codepen.io/aomyers/pen/LWOwpR\r\n____\r\n\r\nWe have not looked at the data set closely enough . it is always only the top 5 surnames per postal code. Sorted by woman and man. So we couldn't just say: These are the top 5 surnames per canton, because we would falsify the evaluation. \r\nSo we decided to simply choose one postcode per canton and selected the data in Google docs and then converted it into a Jason.\r\nThe goal is to create a One pager where you can see one city per canton, which is divided into top 5 men's last names and top 5 women's last names. \r\n____\r\nThe dataset we used: https://opendata.swiss/de/dataset/nachnamen-pro-plz\r\n \r\nFirst steps:\r\n1. Some big cities in Switzerland are not mentioned. That means that the swiss post didn\u2019t collect names there.\r\n1. Some rangs are doubled because of the same number of names on the ranglist. Example: in Kloten are 35 surenames Mueller and 35 surenames J\u00e4ger -> so they show both as rang 5.\r\nFor our project we only can use one name. J\u00e4ger and not Mueller for example. \r\n\r\n2. We made our own list. We had to find out wich is the next big city in the canton. \r\nCheck if there are double rangs and delete it if needed.  \r\n\r\n3. After that, we converted the excel list to a json object. That json-list is now input of our javascript-file.\r\n\r\nNext steps and problems:\r\n4. We recognized, that we need should use a databank. This is unfortunately way out of our programm skillz and would take to much time. \r\n5. RETHINK: How can we still manage that the lists appears?\r\n6. SOLUTION, (thank you brain), -> its possible to show the list female and male on each side, with flexboxes. For that we need to make excel lists for each canton. \r\nWe\u2019ve been working with atom and the integrated teleport package in order to be able to work together.. However, the team member who\u2019s the owner of the files must always be online and always active, or else the invitees cannot access the files.\r\n\r\nTo be more precise: First of all, typed in a connection from the list in HTML to the pictures. They're changinge everytime they got hovered/unhovered. In a next step, we had to implement the .json, what wasn't easy because we didn't use a database so far in the reason of the time range. So we had to create a function, where the locations have to pass through our .json file. forEach() we used also to gather the gender and similar data out of JSON. Right after, we had to create a function for the table title. We had to create a function to read and parse the JSON:\r\n\r\nfunction loadJSON(callback) {\r\n  var xobj = new XMLHttpRequest();\r\n  xobj.overrideMimeType(\"application/json\");\r\n  xobj.open('GET', 'convertcsv.json', true);\r\n  xobj.onreadystatechange = function() {\r\n    console.log(xobj.readyState);\r\n    if (xobj.readyState == 4 && xobj.status == \"200\") {\r\n      // Required use of an anonymous callback as .open will NOT return a value but simply returns undefined in asynchronous mode\r\n      callback(xobj.responseText);\r\n    }\r\n  };\r\n  xobj.send(null);\r\n}\r\n\r\nThis was the most important step to set it up without a database.\r\n\r\nLEARNINGS:\r\nWe got the hint, that it's also possible to work on Github together and we'll definitely going to do that by the next project. \r\nThe programming was kept very easy, as we are only Newbies. \r\nWe made a map with pictures, every canton was one. For the hover we made an overlayer to color the canton red.\r\nWe connected it with a class to the right name button. \r\n","maintainer":"Geruscha Lau FHGR","name":"Swiss Name Chart","phase":"Launch","progress":40,"score":89,"source_url":"https://github.com/mapsname","stats":{"commits":0,"during":25,"people":4,"sizepitch":3973,"sizetotal":4092,"total":25,"updates":20},"summary":"We connect names out of a data set and integrate the data into a map of Switzerland or some other visual form of a map.","team":"Geruscha Lau FHGR, rayyan waldburger, SimoneB., tako_yakii-crypto","team_count":4,"updated_at":"2020-06-06T13:51","url":"https://hack.glam.opendata.ch/project/17","webpage_url":"https://824189-6.web1.fh-htwchur.ch/#"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"https://glamhack2020.slack.com/archives/C014UH7EJCT","created_at":"2020-06-06T10:53","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"###Pitch\r\n\r\nThis project aims to create a friendly user interface to visualize and interact with a dataset of 50'000 exhibitions from SIKART.ch on a world map.\r\n\r\n###Description\r\n\r\nThis is a project realized by Ishan Mishra, using a dataset from the Swiss Institute for Art Research (SIK-ISEA) which contains about 50'000 art exhibitions from SIKART.ch, the online lexicon of SIK-ISEA documenting the activities of artists related to Switzerland, either through nationality or through sustained artis...","hashtag":"","id":20,"ident":null,"image_url":"https://www.dropbox.com/s/8ix8lm0pjqf761r/glam-artexhibitions-image-v1.jpg?raw=1","is_challenge":false,"is_webembed":false,"logo_color":"#e91c93","logo_icon":"","longtext":"###Pitch\r\n\r\nThis project aims to create a friendly user interface to visualize and interact with a dataset of 50'000 exhibitions from SIKART.ch on a world map.\r\n\r\n###Description\r\n\r\nThis is a project realized by Ishan Mishra, using a dataset from the Swiss Institute for Art Research (SIK-ISEA) which contains about 50'000 art exhibitions from SIKART.ch, the online lexicon of SIK-ISEA documenting the activities of artists related to Switzerland, either through nationality or through sustained artistic activity in Switzerland.\r\n\r\n###Dataset\r\n\r\nThe dataset lists each of the 50'000 exhibitions title, start and end date, name of hosting institution, names of participating artists who are documented in SIKART, latitude and longitude data for the exhibition location and link to the respective exhibition entry in SIKART. The dataset is openly available in CSV format here:\r\nhttps://drive.google.com/file/d/1dfqCHxai16hnkAXC_UCiU3b3J9EUHrTQ/view?usp=sharing\r\n\r\n### First draft\r\nA first draft focused on visualizing the density of exhibition activity per year:\r\nhttps://public.tableau.com/profile/ishan.mishra8696#!/vizhome/Artexhibitionsannually/ArtExhibtionsAnnually?publish=yes\r\n\r\n### Final version\r\nThe final result of the hackathon displays the exhibitions on a map and allows the user to filter exhibitions by start and end dates, by artist, and by type of exhibition. It also lists the amount of exhibitions per artist for the filtered result on a chart next to the map:\r\nhttps://public.tableau.com/profile/ishan.mishra8696#!/vizhome/ArtExhibition1945-2020/ArtistDashboard?publish=yes\r\n\r\n### Note on final version and further development\r\nProjects shown through the web version of Tableau Public respond quite slowly to user input like filter changes. The Tableau Public workbook can be downloaded at the above link and opened locally which makes the map much more responsive and also allows for changes to the workbook. Tableau Public was chosen as a freely available software to also allow for further work on the project by those who are interested. The dataset from the link above is also free to be used.\r\n\r\n###Technologies\r\n\r\nTableau Public, Open Refine, CSV\r\n\r\n###Contact\r\nIshan Mishra: ishanmisra200@gmail.com or https://github.com/SnickeyX","maintainer":"GLAMoperator","name":"Art exhibitions, 1945-2020","phase":"Share","progress":50,"score":88,"source_url":"","stats":{"commits":0,"during":38,"people":3,"sizepitch":2255,"sizetotal":2333,"total":42,"updates":38},"summary":"A user-friendly interface to visualize exhibition data from SIKART.ch on a map","team":"GLAMoperator, paulbrunner, Davide","team_count":3,"updated_at":"2020-06-06T21:04","url":"https://hack.glam.opendata.ch/project/20","webpage_url":"https://public.tableau.com/profile/ishan.mishra8696#!/vizhome/ArtExhibition1945-2020/ArtistDashboard?publish=yes"},{"autotext":"","autotext_url":"https://github.com/MartinVollenweider/Europa-meets-Europe","category_id":"","category_name":"","contact_url":"https://app.slack.com/client/T01389WTSSX/C014MJZM1AS","created_at":"2020-06-01T16:45","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"**Description**: In this art project, random images of the Galilean Moon Europe from the NASA archive are overlaid pixel by pixel with current images from European webcams in rhythm with the Jupiter Symphony by Mozart. The art project links and connects the continent of Europe with the 1610 by Galileo Galilei discovered Jupiter moon, which is around 660 million kilometers away. Each time the application is started it loads a new webcam image from Berlin, Rome, Paris, Oslo, Z\u00fcrich or Chur and a n...","hashtag":"","id":9,"ident":null,"image_url":"http://mediapp.ch/glamhack2020/img/startpage.jpg","is_challenge":false,"is_webembed":true,"logo_color":"","logo_icon":"","longtext":"**Description**: In this art project, random images of the Galilean Moon Europe from the NASA archive are overlaid pixel by pixel with current images from European webcams in rhythm with the Jupiter Symphony by Mozart. The art project links and connects the continent of Europe with the 1610 by Galileo Galilei discovered Jupiter moon, which is around 660 million kilometers away. Each time the application is started it loads a new webcam image from Berlin, Rome, Paris, Oslo, Z\u00fcrich or Chur and a new image from Europa. There is never the same combination.\r\n\r\n**Data**: The dynamic images of Europe are accessed via the [NASA API](https://api.nasa.gov/), the webcams via the [Windy API](https://api.windy.com/webcams/docs). In the current version the music from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Wolfgang_Amadeus_Mozart_-_Symphony_No._41_4th_Movement_(Jupiter),_K.551.ogg) is directly loaded from the web server.\r\n\r\n**Technology**: HTML, Javascript, P5.js and PHP\r\n\r\n**Current version**: The current version achieves the goals set at the beginning of the GLAM hack 2020.\r\n\r\n**Future improvements**: depending on the two dynamically loaded pictures the sizes are not equal. They have to be resized.\r\n\r\n**Main difficulty**: At the beginning the error *access to fetch at ... from origin ... has been blocked by CORS policy* appeared when loading the NASA pictures with Javascript. The solution was to save to pictures dynamically to the web server with Javascript.\r\n\r\n**[Link to PDF](https://mediapp.ch/glamhack2020/documentation/2020_glamhack_presentation.pdf)**\r\n\r\n**Contact**: [Martin Vollenweider](mailto:martin.vollenweider@fhgr.ch)","maintainer":"mv24","name":"Europa meets Europe ","phase":"Share","progress":50,"score":87,"source_url":"https://github.com/MartinVollenweider/Europa-meets-Europe","stats":{"commits":0,"during":7,"people":1,"sizepitch":1663,"sizetotal":1761,"total":10,"updates":8},"summary":"Art project that connects the Jupiter moon Europa with the continent Europe thru the help of APIs.","team":"mv24","team_count":1,"updated_at":"2021-07-06T20:05","url":"https://hack.glam.opendata.ch/project/9","webpage_url":"https://mediapp.ch/glamhack2020"},{"autotext":"GLAMhack 2020 - Culture inTime\n=========================\nSimple event calendar for public viewing written in Rails, SPARQL and Semantic UI (web interface platform). Using existing linked open data (LOD) on productions & events, locations & venues, and dates to feed contemporary and historical data into this calendar. Coming soon: LOD on artists and works. \n\nGo to https://culture-intime.herokuapp.com/ and view calendar\n\n![Home Page](https://raw.githubusercontent.com/saumier/GLAMhack2020-Culture-inTime/master/images/HomePage.png)\n\n\n\n\nData Sources\n=========================\nBuilding on existing data sources:\n* Dataset already integrated into Wikidata: data from Schauspielehaus, Zurich. For reference see: https://www.wikidata.org/wiki/Wikidata:WikiProject_Performing_arts/Reports/Ingesting_Production_Databases_of_the_Performing_Arts\n* Dataset from [Artsdata.ca](http://artsdata.ca): pan-Canadian knowledge graph for the performing arts \n\n\nBackground\n=========================\nThis 2020 GlamHack Challenge resulted from the discussions we had earlier this week during the workshops related to performing arts data and our goal is to create a Linked Open Data Ecosystem for the Performing Arts.\n\nSome of us have been working on this for years, focusing mostly on data cleansing and data publication.\nNow, the time has come to shift our focus towards creating concrete applications that consume data from different sources.\nThis will allow us to demonstrate the power of linked data and to start providing value to users.\nAt the same time, it will allow us to tackle issues related to data modelling and data federation based on concrete use cases.\n\n\u201cCulture InTime\u201d is one such application. It is a kind of universal cultural calendar, which allows us to put the Spotlight on areas and timespans where coherent sets of data have already been published as linked data. At the same time, the app fetches data from living data sources on the fly. And as more performing arts data is being added to these data sources, they will automatically show up.\nIt can:\n- Provide a robust listing of arts and cultural events, both historical and current. Audiences are able to search for things they are interested in, learn more about performing arts productions and events, find new interests, et cetera.\n- Reduce duplication of work in area of data entry\n\nThe code is a simple as possible to demonstrate the potential of using LOD (structured data) to create a calendar for arts and cultural events that is generated from data in Wikidata and the [Artsdata.ca](http://artsdata.ca) knowledge graph. \n\nThe user interface is designed to allow visitors to search for events. They can:\n- Use the Spotlight feature to quickly view events based on the following search criteria: name of city and predetermined date range.\n- Use Time Period buttons to search a time period (international).\n- Use a Search field to enter a search using the following criteria: name of production, theatre, city, or country.\n- Select an image from a gallery to find related information.\n- Visit the source of the data to learn more (in the example of an Artsdata.ca event, Click Visit Event Webpage to be redirected to the Art Organization website.\n\nNote: Currently when you enter a location, data only exists for Switzerland and Canada (country), Zurich, Montreal/Laval/Toronto/Vancouver/Fredericton and some small villages in Quebec.  \n\nSearch results list events sorted by date.\n\n\nChallenges\n=========================\nData is modelled differently in Wikidata, Artsdata, and even between projects within the same database.\nData has very few images.\n\nMore UI Images\n=========================\nSpotlight Page\n\n![Spotlight Page](https://raw.githubusercontent.com/saumier/GLAMhack2020-Culture-inTime/master/images/Spotlight.png)\n\nEvent Details page - Montreal\n\n![Production Details](https://raw.githubusercontent.com/saumier/GLAMhack2020-Culture-inTime/master/images/ProductionDetails.png)\n\nProduction Details page - Zurich\n\n![Production Details](https://raw.githubusercontent.com/saumier/GLAMhack2020-Culture-inTime/master/images/ProductionDetails-Schauspielhaus-Zurich.png)\n","autotext_url":"https://github.com/saumier/GLAMhack2020-Culture-inTime","category_id":"","category_name":"","contact_url":"https://glamhack2020.slack.com/archives/C0150GLV03E","created_at":"2020-06-04T14:59","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"GLAMhack 2020 - Culture inTime\n=========================\nSimple event calendar for public viewing written in Rails, SPARQL and Semantic UI (web interface platform). Using existing linked open data (LOD) on productions & events, locations & venues, and dates to feed contemporary and historical data into this calendar. Coming soon: LOD on artists and works. \n\nGo to https://culture-intime.herokuapp.com/ and view calendar\n\n![Home Page](https://raw.githubusercontent.com/saumier/GLAMhack2020-Culture-i...","hashtag":"","id":11,"ident":null,"image_url":"https://raw.githubusercontent.com/saumier/GLAMhack2020-Culture-inTime/master/images/Screen%20Shot%202020-06-06%20at%209.12.09%20AM.png","is_challenge":false,"is_webembed":false,"logo_color":"#e0dc85","logo_icon":"","longtext":"\r\n","maintainer":"saumier","name":"Culture in Time","phase":"Launch","progress":40,"score":86,"source_url":"https://github.com/saumier/GLAMhack2020-Culture-inTime","stats":{"commits":0,"during":11,"people":2,"sizepitch":0,"sizetotal":4235,"total":24,"updates":21},"summary":"Cultural Calendar using existing LOD on past and future productions, venues, artists, and works.","team":"saumier, beatestermann","team_count":2,"updated_at":"2020-09-15T12:41","url":"https://hack.glam.opendata.ch/project/11","webpage_url":"https://culture-intime.herokuapp.com/"},{"autotext":"","autotext_url":"https://234194-8.web1.fh-htwchur.ch/front-page.html","category_id":"","category_name":"","contact_url":"https://glamhack2020.slack.com/archives/C015LNPNQ8G","created_at":"2020-06-05T09:07","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"In our project want to focus on the beauty of nature, that\u2018s why we decided to use the dataset \u00abThe Call of the Mountains\u00bb. \r\nOur aim is to generate an interactive map, which allows the user to quickly get an overview of the mountains around \u00abGraub\u00fcnden\u00bb.\r\n\r\nFrontpage (Map of Mountains)\r\n-The map consists of several districts. After selecting one area, the user is able to see different suggestions -  inside the selected district.\r\n\r\nSubpage1 (Variety of Cards)\r\n-After clicking the \"See More\"-but...","hashtag":"","id":16,"ident":null,"image_url":"http://make.opendata.ch/wiki/_media/glam:capauliana_belveder_13931.1.jpg?cache=","is_challenge":false,"is_webembed":true,"logo_color":"","logo_icon":"","longtext":"In our project want to focus on the beauty of nature, that\u2018s why we decided to use the dataset \u00abThe Call of the Mountains\u00bb. \r\nOur aim is to generate an interactive map, which allows the user to quickly get an overview of the mountains around \u00abGraub\u00fcnden\u00bb.\r\n\r\nFrontpage (Map of Mountains)\r\n-The map consists of several districts. After selecting one area, the user is able to see different suggestions -  inside the selected district.\r\n\r\nSubpage1 (Variety of Cards)\r\n-After clicking the \"See More\"-button the user is directed to the first subpage.\r\n-There will be shown a variety of different mountains - located in the chosen district and displayed as cards.\r\n\r\nSubpage2 (Personal Choice)\r\n-Once the user made his choice, he can get more details by using the \"See Profile\"-button.\r\n-This leads to a second subsite, where the image of the selected mountain-card appears in full size\r\n-Also more information about the background and location are visible.\r\n\r\n\r\nContact: Mirjam Rodehacke & Nicole Nett (students at FHGR)\r\nData Source: Fundaziun Capauliana","maintainer":"nicolenett","name":"\u00abMATCH WITH THE MOUNTAINS\u00bb","phase":"Launch","progress":40,"score":85,"source_url":"https://234194-8.web1.fh-htwchur.ch/front-page.html","stats":{"commits":0,"during":22,"people":2,"sizepitch":1051,"sizetotal":1130,"total":22,"updates":19},"summary":"We'd like to introduce the best matching mountain according to the users needs.","team":"nicolenett, sense8","team_count":2,"updated_at":"2020-06-06T17:30","url":"https://hack.glam.opendata.ch/project/16","webpage_url":"https://docs.google.com/document/d/e/2PACX-1vQX7kZUXbhgPIN7bB3XiYyWLBcyy4SLjt3StLPxhGBNX0LgzBMe-rcX01V9aXXMWxFGJa0m6P-0Civb/pub"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"mailto:thomas.weibel@bluewin.ch","created_at":"2020-05-11T11:26","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"<a href=\"https://thomasweibel.ch/swissar/\" target=\"_blank\">swissAR</a> is a project based upon <a href=\"https://www.thomasweibel.ch/topo/\" target=\"_blank\">Toposwiss</a>, a Virtual Reality model of Switzerland. swissAR is a mobile web app providing geographical information about the user's surroundings. Like Toposwiss, it is driven by an <a href=\"https://opendata.swiss/de/dataset/das-digitale-hohenmodell-der-schweiz-mit-einer-maschenweite-von-200-m\" target=\"_blank\">open-data digital elevation mod...","hashtag":"","id":4,"ident":null,"image_url":"https://www.thomasweibel.ch/data/uploads/news/swissar_kl.png","is_challenge":false,"is_webembed":false,"logo_color":"#008040","logo_icon":"","longtext":"<a href=\"https://thomasweibel.ch/swissar/\" target=\"_blank\">swissAR</a> is a project based upon <a href=\"https://www.thomasweibel.ch/topo/\" target=\"_blank\">Toposwiss</a>, a Virtual Reality model of Switzerland. swissAR is a mobile web app providing geographical information about the user's surroundings. Like Toposwiss, it is driven by an <a href=\"https://opendata.swiss/de/dataset/das-digitale-hohenmodell-der-schweiz-mit-einer-maschenweite-von-200-m\" target=\"_blank\">open-data digital elevation model</a> (DEM) published by the Swiss federal office of topography and by <a href=\"https://www.swisstopo.admin.ch/de/wissen-fakten/toponymie.html\" target=\"_blank\">toponymy databases</a> listing Swiss city and village names, postcodes, mountain peaks, cultural heritage sites, bus and railway stations, sports facilities etc.\r\n\r\n<h3>Instructions</h3>\r\n<img src=\"https://www.thomasweibel.ch/data/uploads/news/qr_swissar.png\" height=\"200\" width=\"200\" style=\"position: relative; top: 10px; float: left; margin: 0 20px 10px 0;\" />Launch your camera app, hold your smartphone upright and point it towards the QR code. Confirm website access, camera access, geolocation and motion sensor access. Hold still during calibration. As soon as swissAR displays the information you can turn around and discover any point of interest within a range of 10 kilometers.\r\n\r\nIn the center a compass will indicate your current heading. The buttons at the bottom allow for adjusting the height of the virtual camera. Tap on the arrow-up button in order to lift the cam by 1000 meters or the arrow-down button to lower it respectively; on the bottom left a cam height indicator will display your current virtual height above ground level. Hit the reload button to recalibrate the app if needed.\r\n\r\n<h3>Settings</h3>\r\nTo avoid the camera and geolocation confirm dialogs on startup you can adjust your smartphone settings.\r\n<ul>\r\n<li><strong>iOS Safari:</strong> Go to\r\n<ul>\r\n<li>Settings > Safari > Location Services > Allow</li>\r\n<li>Settings > Safari > Camera > Allow</li>\r\n</ul>\r\n</li>\r\n<li><strong>Android Chrome:</strong> Go to\r\n<ul>\r\n<li>Chrome > Settings > Location > Allowed</li>\r\n<li>Chrome > Settings > Camera > Allowed</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n\r\n<h3>Technical</h3>\r\n<img src=\"https://www.thomasweibel.ch/data/uploads/news/swissar_kl.png\" height=\"338\" width=\"200\" style=\"position: relative; top: 10px; float: left; margin: 0 20px 10px 0;\" />On startup swissAR will launch the camera, retrieve geolocation data, current compass heading and access motion sensor data. It will then process the elevation model in order to determine the user's height above sea level and any relevant point of interest within a given distance. swissAR will work anywhere in Switzerland; outside Switzerland it will take you to Berne (or any other place when using parameters, see below). swissAR does not store any kind of user or session data, neither on the device nor on the web server.\r\n\r\nswissAR has been built with <a href=\"https://aframe.io/\" target=\"_blank\">A-Frame</a> and the Augmented Reality component <a href=\"https://aframe.io/blog/arjs/\" target=\"_blank\">AR.js</a>. A-Frame XR projects are rendered by any major web browser and on any platform. Yet, swissAR has been designed for mobile use and will not work on desktop computers properly due to the lack of a rear camera or motion sensors.\r\n\r\n<h3>Geography</h3>\r\nswissAR makes use of the HTML 5 geolocation API. The output (world geodetic format, in decimal degrees) must be converted into Swiss coordinates (zero point in Berne, see below), the javascript processing of which is as follows:\r\n\r\n<code>navigator.geolocation.getCurrentPosition(function(position) { // HTML 5 geolocation API<br />\r\n&nbsp;&nbsp;&nbsp;var n, e;<br />\r\n&nbsp;&nbsp;&nbsp;var b1=position.coords.latitude&lowast;3600; // conversion algorithm<br />\r\n&nbsp;&nbsp;&nbsp;var l1=position.coords.longitude&lowast;3600;<br />\r\n&nbsp;&nbsp;&nbsp;var b2=(b1-169028.66)/10000;<br />\r\n&nbsp;&nbsp;&nbsp;var l2=(l1-26782.5)/10000;<br />\r\n&nbsp;&nbsp;&nbsp;n=200147.07+308807.95&lowast;b2+3745.25&lowast;Math.pow(l2,2)+76.63&lowast;Math.pow(b2,2)+119.79&lowast;Math.pow(b2,3)-194.56&lowast;Math.pow(l2,2)&lowast;b2;<br />\r\n&nbsp;&nbsp;&nbsp;e=600072.37+211455.93&lowast;l2-10938.51&lowast;l2&lowast;b2-0.36&lowast;l2&lowast;Math.pow(b2,2)-44.54&lowast;Math.pow(l2,3);<br />\r\n}</code>\r\n\r\nThe coordinates will then be rounded and matched against the DEM grid (<a href=\"https://de.wikipedia.org/wiki/Schweizer_Landeskoordinaten#Umrechnung_WGS84_auf_CH1903\" target=\"_blank\">further information</a> on Wikipedia). Finally the scenery is aligned to the current compass heading which can be retrieved as follows (cross-platform solution):\r\n\r\n<code>window.addEventListener(\"deviceorientation\", function(e) { // get current compass heading<br />\r\n&nbsp;&nbsp;&nbsp;var heading;<br />\r\n&nbsp;&nbsp;&nbsp;if (e.webkitCompassHeading) heading=e.webkitCompassHeading; // get webkit compass heading<br />\r\n&nbsp;&nbsp;&nbsp;else heading=e.alpha; // get android compass heading<br />\r\n});</code>\r\n\r\n\r\n<h3 id=\"parameters\">Parameters</h3>\r\nswissAR is parametrizable in order to access locations other than the current one. Valid parameters are place names (case sensitive), postcodes or plain coordinates.\r\n\r\n<ul>\r\n<li><code>thomasweibel.ch/swissar</code> (geolocation accepted) &rarr; current location</li>\r\n<li><code>thomasweibel.ch/swissar</code> (geolocation denied, or outside Switzerland) &rarr; zero point of the Swiss coordinate system (600&nbsp;000 E/200&nbsp;000 N) at the old astronomical observatory of the University of Berne</li>\r\n<li><code>thomasweibel.ch/swissar?ort=Chur</code> &rarr; Chur, Canton of Grisons</li>\r\n<li><code>thomasweibel.ch/swissar?plz=8001</code> &rarr; Zurich</li>\r\n<li><code>thomasweibel.ch/swissar?lon=637071&lat=161752</code> &rarr; Wengen, Canton of Berne</li>\r\n</ul>\r\n\r\n<h3>Data</h3>\r\n<ul>\r\n<li>opendata.swiss: <a href=\"https://opendata.swiss/de/dataset/das-digitale-hohenmodell-der-schweiz-mit-einer-maschenweite-von-200-m\" target=\"_blank\">Digital elevation model</a></li>\r\n<li>opendata.swiss: <a href=\"https://opendata.swiss/de/dataset/amtliches-ortschaftenverzeichnis-mit-postleitzahl-und-perimeter\" target=\"_blank\">Place name and postcode database</a></li>\r\n<li>opendata.swiss: <a href=\"https://opendata.swiss/de/dataset/swissnames3d-geografische-namen-der-landesvermessung-inspire\" target=\"_blank\">Toponymy database</a> (<a href=\"https://www.swisstopo.admin.ch/content/swisstopo-internet/de/home/products/height/dhm25/_jcr_content/contentPar/tabs/items/dokumente/tabPar/downloadlist/downloadItems/868_1464696772548.download/dhm25infode.pdf\" target=\"_blank\">further information</a> by the Swiss federal office of topography)</li>\r\n<li>thomasweibel.ch: <a href=\"https://www.thomasweibel.ch/swissar/pdf/presentation.pdf\" target=\"_blank\">Project presentation</a> (pdf), June 6, 2020</li>\r\n</ul>\r\n\r\n<h3>Contact</h3>\r\n<a href=\"https://www.thomasweibel.ch\" target=\"_blank\">Thomas Weibel</a>","maintainer":"twb","name":"swissAR","phase":"Share","progress":50,"score":84,"source_url":"","stats":{"commits":0,"during":46,"people":1,"sizepitch":7004,"sizetotal":7106,"total":96,"updates":94},"summary":"swissAR is an augmented reality web app displaying relevant information about the user's surroundings.","team":"twb","team_count":1,"updated_at":"2020-08-29T14:15","url":"https://hack.glam.opendata.ch/project/4","webpage_url":"https://www.thomasweibel.ch/swissar/"},{"autotext":"","autotext_url":"https://github.com/parisdata/GLAMhack2020","category_id":"","category_name":"","contact_url":"https://github.com/parisdata/GLAMhack2020/issues","created_at":"2020-06-01T06:51","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"<b>The Question:</b> How to sift through the millions of objects in museums to identify top priorities for intensive research by humans?\r\n<br><b>The Goal:</b> Automatically Classify and Rank 70,000 art provenance texts by probability that further research will turn up a deliberately concealed history of looting, forced sale, theft or forgery.\r\n<br><b>The Challenge:</b> Analyse texts <i>quickly</i> for Red Flags, quantify, detect patterns, classify, rank, and learn. Whatever it takes to produce a...","hashtag":"","id":7,"ident":null,"image_url":"","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"<b>The Question:</b> How to sift through the millions of objects in museums to identify top priorities for intensive research by humans?\r\n<br><b>The Goal:</b> Automatically Classify and Rank 70,000 art provenance texts by probability that further research will turn up a deliberately concealed history of looting, forced sale, theft or forgery.\r\n<br><b>The Challenge:</b> Analyse texts <i>quickly</i> for Red Flags, quantify, detect patterns, classify, rank, and learn. Whatever it takes to produce a reliable list of top suspects</p>\r\n\r\n\r\n<br>For this challenge several datasets will be provided.\r\n<br>\r\n<br>1) DATASET:70,000 art provenance texts for analysis\r\n<br>2) DATASET: 1000 Red Flag Names \r\n<br>3) DATESET: 10 Key Words or Phrases </b>\r\n<br>\r\n<br>\r\n<i>TRIAGE: You're the doctor and the texts are your patients! Who's in good health and who's sick? How sick? With what disease? What kind of tests and measurements can we perform on the texts to help us to reach a diagnosis? What kind of markers for should we look for? How to look for them?</i>\r\n<br>\r\n<div style=\"caret-color: rgb(102, 102, 102); color: #666666; font-family: &quot;Trebuchet MS&quot;, Trebuchet, Verdana, sans-serif;\">\r\n<span style=\"background-color: #fff2cc; font-family: &quot;georgia&quot; , &quot;times new roman&quot; , serif;\"><a href=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vRym_6MZgcbwOagNt1YHEx0ZRDQLGy-206lWbzCZ9u30Yddj2qfvUzeKmlg02QZJb3lgNrKY3gMm2-a/pub?gid=176631427&amp;single=true&amp;output=csv\" style=\"color: #888888; text-decoration: none;\"><span style=\"font-size: x-large;\"><u>Download &nbsp;Provenance Texts Dataset: CSV&nbsp;</u></span></a></span></div>\r\n<br>\r\nSee code at https://github.com/parisdata/GLAMhack2020\r\n","maintainer":"LaZu","name":"Text Analysis Challenge: Detect Looted Art.","phase":"Launch","progress":40,"score":80,"source_url":"https://www.openartdata.org/2020/06/art-provenance-dataset-text-analysis.html","stats":{"commits":0,"during":1,"people":1,"sizepitch":1719,"sizetotal":1833,"total":19,"updates":17},"summary":"Help Automate Analysis, Flagging and Ranking of Museum Art Provenance Texts by the Probability of a Hidden History","team":"LaZu","team_count":1,"updated_at":"2020-06-21T09:45","url":"https://hack.glam.opendata.ch/project/7","webpage_url":"https://www.openartdata.org/2020/06/art-provenance-dataset-text-analysis.html"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2020-06-04T12:09","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"The PTT archive is increasingly digitising its collections with the aim of not only making documents more easily available, but also of making them accessible, linked and analysed in new ways. Many of these Documents can be assigned to one or more geographical points. Three such records are presented below, with the idea of trying out new approaches and concepts:\r\n\r\n*[Poststellenchroniken](https://opendata.swiss/de/dataset/metadaten-poststellenchroniken):* This OpenRefine dataset contains an ext...","hashtag":"","id":10,"ident":null,"image_url":"https://i.imgur.com/CGItUEF.jpg","is_challenge":false,"is_webembed":true,"logo_color":"","logo_icon":"","longtext":"The PTT archive is increasingly digitising its collections with the aim of not only making documents more easily available, but also of making them accessible, linked and analysed in new ways. Many of these Documents can be assigned to one or more geographical points. Three such records are presented below, with the idea of trying out new approaches and concepts:\r\n\r\n*[Poststellenchroniken](https://opendata.swiss/de/dataset/metadaten-poststellenchroniken):* This OpenRefine dataset contains an extract of the archive database with metadata on the post office chronicles stored in the PTT archive. The post office chronicles contain collected information, partly also newspaper clippings, photos and plans of all historical post offices of the PTT. The archive database entries for each dossier were prepared in OpenRefine, assigned to a post office (there are sometimes several dossiers per post office) and then linked to the corresponding current administrative communities on Wikidata via OpenRefine's Reconciliation Service. This linkage is currently not yet fully completed. The aim is firstly to record entries for the post offices on Wikidata itself, and secondly to enable a rough geo-referencing of the post offices via the link to the municipalities, which would otherwise only be possible via a time-consuming, manual re-listing.\r\n\r\n*[Postkurskarten](https://opendata.swiss/de/dataset/postkurskarten):* The dataset contains a selection of retro-digitized \"Postkurskarten\" of the Swiss PTT between 1851 and 1941, providing information on postal connections and the respective departure and arrival times. The older maps depict the entire network of postal connections (stage coaches and later also railway and post bus services), while the more recent maps are somewhat more schematic. The selection presented here gives an impression of the maps archived in the PTT archive. However, there is a large number of other maps (also on telecommunications) with a different geographical focus and covering the entire period of existence of the PTT. The file names correspond to the archive signature of the course charts.\r\nThe \"Postkurskarten\" are to be digitally annotated. Where possible, this should be done automatically (e.g. via text recognition) or via easy to use public collaborative tools. Maps prepared in this way could then be used for assigning/linking other archive documents on them geographically.\r\n\r\n*[Postauto Postkarten](https://opendata.swiss/de/dataset/postauto-postkarten):* The data set contains a selection of retro-digitized postbus postcards from the PTT archive. These postcards each show Postbuses on known routes, especially pass lines. They were produced by the PTT for advertising purposes. Also here, possible methods for georeferencing shall be experimented with. These references can then be linked and localized with the annotated maps.","maintainer":"n.kessler","name":"Georeferencing and linking digitized archival Documents","phase":"Launch","progress":40,"score":72,"source_url":"","stats":{"commits":0,"during":3,"people":2,"sizepitch":2880,"sizetotal":2880,"total":10,"updates":7},"summary":"","team":"n.kessler, Nobu","team_count":2,"updated_at":"2020-06-29T07:20","url":"https://hack.glam.opendata.ch/project/10","webpage_url":"https://docs.google.com/document/d/e/2PACX-1vSAsvWJ9bivqKtWqAHBEzGYu5wF0jj9W95XtSsqv-hcpfI8TJgNRVxNa6a0z-BgUxzTTP_oHLqmt3bQ/pub?embedded=true"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2020-05-07T13:35","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"Each year, the GLAMhack brings to life fascinating projects created by fascinating people! Before the hackathon, the participants usually don't know what to expect. After the hackathon, their minds are full of inspiration, new ideas and good memories (at least we hope so). \r\n\r\nPeople who have never been to a hackathon often find it very difficult to imagine what actually \"happens\" during the event and that usually represents an obstacle for them to make the big step and participate for the first...","hashtag":"","id":3,"ident":null,"image_url":"","is_challenge":false,"is_webembed":true,"logo_color":"","logo_icon":"","longtext":"Each year, the GLAMhack brings to life fascinating projects created by fascinating people! Before the hackathon, the participants usually don't know what to expect. After the hackathon, their minds are full of inspiration, new ideas and good memories (at least we hope so). \r\n\r\nPeople who have never been to a hackathon often find it very difficult to imagine what actually \"happens\" during the event and that usually represents an obstacle for them to make the big step and participate for the first time. This challenge wants to solve this situation by providing a aftermovie of the hackathon's atmosphere, of the teams and their interactions, of the projects and the processes involved towards their realisation.\r\n\r\n**Challenge:** Create an aftermovie of the GLAMhack20! The aftermovie should be fun to watch and give an idea of the hackathon's essence to people who have never been to a GLAMhack.","maintainer":"GLAMoperator","name":"#GLAMhack Aftermovie","phase":"Prototype","progress":30,"score":62,"source_url":"","stats":{"commits":0,"during":3,"people":2,"sizepitch":900,"sizetotal":960,"total":7,"updates":4},"summary":"Create an insight into the GLAMhack20 for the broad audience","team":"GLAMoperator, Demian","team_count":2,"updated_at":"2020-08-13T06:37","url":"https://hack.glam.opendata.ch/project/3","webpage_url":"https://www.youtube.com/embed/u1Pgu7yxzEU"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"https://app.slack.com/client/T01389WTSSX/C014FPW1DJT/","created_at":"2020-04-28T15:25","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"We worked on ideas for enabling access to archive data using chatbots, which you can interact with right inside of the official chat platform of #GLAMhack2020. Details and screenshots are in the notebook.\r\n\r\nhttps://github.com/dribdat/dridbot/pull/5","hashtag":"","id":1,"ident":null,"image_url":"https://github.com/dribdat/dridbot/raw/935dd027291a40e15b5ea12733a4d027b281182a/images/Logo_of_GlamBot.svg.png","is_challenge":false,"is_webembed":false,"logo_color":"#e6ba99","logo_icon":"","longtext":"We worked on ideas for enabling access to archive data using chatbots, which you can interact with right inside of the official chat platform of #GLAMhack2020. Details and screenshots are in the notebook.\r\n\r\nhttps://github.com/dribdat/dridbot/pull/5","maintainer":"loleg","name":"Sir Dridbot Glamhacker","phase":"Launch","progress":40,"score":57,"source_url":"https://github.com/hackathons-ftw/dridbot/tree/glamhack2020","stats":{"commits":0,"during":4,"people":2,"sizepitch":249,"sizetotal":291,"total":8,"updates":5},"summary":"Surfacing archival open data with chatbots","team":"loleg, jeremy","team_count":2,"updated_at":"2022-10-03T19:50","url":"https://hack.glam.opendata.ch/project/1","webpage_url":"https://md.schoolofdata.ch/s/lHGmrMTjd#"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"https://glamhack2020.slack.com/archives/C014T044ETX","created_at":"2020-05-04T09:28","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"Switzerland has a great ammount of libraries, archives and museums, but we are still missing a common directory of all these heritage institutions.\r\n\r\n**Challenge:** The goal is to create a complete inventory of Swiss libraries, archives and museums and to find a solution for the data maintenance of this directory.\r\n\r\n**Vision:** The \"ideal\" directory of Swiss GLAMs is up-to-date, complete, user-friendly, internationally compatible and structured. The contents are indexed and categorized, access...","hashtag":"","id":2,"ident":null,"image_url":"","is_challenge":false,"is_webembed":true,"logo_color":"","logo_icon":"","longtext":"Switzerland has a great ammount of libraries, archives and museums, but we are still missing a common directory of all these heritage institutions.\r\n\r\n**Challenge:** The goal is to create a complete inventory of Swiss libraries, archives and museums and to find a solution for the data maintenance of this directory.\r\n\r\n**Vision:** The \"ideal\" directory of Swiss GLAMs is up-to-date, complete, user-friendly, internationally compatible and structured. The contents are indexed and categorized, accessible to people and machine readable. Information about the collections and opening hours are included and a differentiated accessibility is ensured.\r\n\r\n**Scope:** The directory could be used for the compilation of statistics, for research on collection holdings, institutions and/or events (research, reference works, tourism). \r\n","maintainer":"GLAMoperator","name":"GLAM Inventory","phase":"Research","progress":10,"score":54,"source_url":"https://opendata.swiss/de/dataset/isplus","stats":{"commits":0,"during":5,"people":3,"sizepitch":827,"sizetotal":870,"total":16,"updates":12},"summary":"An inventory of all Swiss GLAM institutions","team":"GLAMoperator, Daniel, Matthias","team_count":3,"updated_at":"2020-06-08T06:50","url":"https://hack.glam.opendata.ch/project/2","webpage_url":"https://md.schoolofdata.ch/s/O54UkeSId#"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2020-06-06T09:24","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"MountainHunt is about providing geodata on old images. From a collection of 179 Pictures, that were taken between 1800 and 2000, you can choose one and try to find its origin. Them recreate it as good as you can and upload the new Version. On that way, we collect Geo-Data on the old Pictures. We crate a time-machine for everyone to join and experience. ","hashtag":"","id":19,"ident":null,"image_url":"","is_challenge":false,"is_webembed":true,"logo_color":"","logo_icon":"","longtext":"MountainHunt is about providing geodata on old images. From a collection of 179 Pictures, that were taken between 1800 and 2000, you can choose one and try to find its origin. Them recreate it as good as you can and upload the new Version. On that way, we collect Geo-Data on the old Pictures. We crate a time-machine for everyone to join and experience. ","maintainer":"Dynamo","name":"MountainHunt","phase":"Sketching","progress":20,"score":50,"source_url":"https://github.com/jnussbaum/mountainhunt","stats":{"commits":0,"during":2,"people":1,"sizepitch":354,"sizetotal":430,"total":2,"updates":0},"summary":"Try to find on old photos the places, where they were taken and recreate it. ","team":"Dynamo","team_count":1,"updated_at":"2020-06-06T09:24","url":"https://hack.glam.opendata.ch/project/19","webpage_url":"https://459900-6.web1.fh-htwchur.ch/"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2020-06-06T11:45","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"Developing digital learning in creative subjects by using paintings of childrens drawings or part of it of the collection Pestalozzianum. \r\nWe started with the question: How can we interact more with the people and maybe enrich the childrens drawings of the Pestalozzianum with more information? \r\n3 cases are developed to make the web space of the collection more vivid, encourage children to interact and activate their fantasy.  \r\nMain challenge: How to learn effectively? (by the spirit of Pestal...","hashtag":"","id":21,"ident":null,"image_url":"https://make.opendata.ch/wiki/_media/glam:scratch_screenshot2.png","is_challenge":true,"is_webembed":false,"logo_color":"#2eb2aa","logo_icon":"","longtext":"Developing digital learning in creative subjects by using paintings of childrens drawings or part of it of the collection Pestalozzianum. \r\nWe started with the question: How can we interact more with the people and maybe enrich the childrens drawings of the Pestalozzianum with more information? \r\n3 cases are developed to make the web space of the collection more vivid, encourage children to interact and activate their fantasy.  \r\nMain challenge: How to learn effectively? (by the spirit of Pestalozzi)\r\n\r\nContact: Sylvia Petrovic-Majer (sylviainpublic@gmail.com)","maintainer":"sylviainpublic","name":"Interactive Storytelling Across Generations","phase":"Challenge","progress":0,"score":44,"source_url":"https://wbd.ms/share/v2/aHR0cHM6Ly93aGl0ZWJvYXJkLm1pY3Jvc29mdC5jb20vYXBpL3YxLjAvd2hpdGVib2FyZHMvcmVkZWVtLzQ0YTY0ZjgyYzc0YjQxYzU4YzQyNWRhOTIxMmM1ODljX0JCQTcxNzYyLTEyRTAtNDJFMS1CMzI0LTVCMTMxRjQyNEUzRA==","stats":{"commits":0,"during":7,"people":1,"sizepitch":566,"sizetotal":614,"total":9,"updates":7},"summary":"Developing digital learning in creative subjects ","team":"sylviainpublic","team_count":1,"updated_at":"2020-06-08T06:52","url":"https://hack.glam.opendata.ch/project/21","webpage_url":"https://drive.google.com/drive/folders/1RPN6oYb4KkxfbXP5lfULtESIBeuAk84f"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2020-06-01T09:10","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"**Challenge**: COVID19 is restricting and changing the way we can access buildings and we can experience space. For safety reasons, access to museums and cultural sites is strictly regulated and complex. \r\n\r\n**Vision**: The outdoors represent a meaningful extension of museums and cultural sites. Connecting a building with the outdoors allows a different experience of the museum, its physical space and its collection. \r\n \r\n**Objective**: Visualizing the ecosystem of connections of museums and cul...","hashtag":"","id":8,"ident":null,"image_url":"","is_challenge":true,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"**Challenge**: COVID19 is restricting and changing the way we can access buildings and we can experience space. For safety reasons, access to museums and cultural sites is strictly regulated and complex. \r\n\r\n**Vision**: The outdoors represent a meaningful extension of museums and cultural sites. Connecting a building with the outdoors allows a different experience of the museum, its physical space and its collection. \r\n \r\n**Objective**: Visualizing the ecosystem of connections of museums and cultural sites, by linking the building of the museum and cultural site to the outdoors. Combining data related to the collections to the original location of the objects, existing itineraries, potential venues, morphology of the territory, municipalities, mobility, infrastructure. Generating opportunities to create new itineraries (i.e. ethnographic, artistic, historical itineraries\u2026) and new temporary exhibitions, dislocation of objects\u2026 We will focus on Ticino and on a series of examples.\r\n\r\n**Data available** \r\n\r\n*Data we are currently uploading on openswiss.data*\r\n\r\nList of cultural operators in Ticino released by Osservatorio culturale del Cantone Ticino (DECS, Repubblica e Cantone Ticino) https://it.wikipedia.org/wiki/Wikipedia:Raduni/Prova_il_tasto_modifica/Elenco\r\n\r\nData on Val Piora released by the Cantonal Museum of Natural History of Lugano (rocks, flora, fauna, landscape, water)\r\n\r\nData on the Verzasca Valley released by the Museum of Val Verzasca (ethnographic itineraries, past exhibitions, museum collection)\r\n\r\nData on Leventina released Museum of Leventina (museum collection, past exhibitions)\r\n\r\nData on Neuralrope#1, permanent interactive installation at the pedestrian tunnel of Besso, Lugano, released by the municipality of Lugano (interaction of the public and daily passages).\r\n\r\n*We have already uploaded in 2018*\r\n\r\nOn OpenStreetMap the repository made by the Osservatorio culturale del Cantone Ticino enriched with locations suggested by citizens\r\n\r\nOn Wikidata a selection of cultural institutions part of the repository made by Osservatorio culturale del Cantone Ticino\r\n\r\n","maintainer":"marta.pucciarelli","name":"Extra Moenia  ","phase":"Challenge","progress":0,"score":20,"source_url":"","stats":{"commits":0,"during":1,"people":1,"sizepitch":2111,"sizetotal":2144,"total":8,"updates":6},"summary":"Fuori le mura / Outside the walls","team":"marta.pucciarelli","team_count":1,"updated_at":"2020-06-05T14:07","url":"https://hack.glam.opendata.ch/project/8","webpage_url":""},{"autotext":"","autotext_url":"https://archive.kirchen.ch/","category_id":"","category_name":"","contact_url":"","created_at":"2020-05-24T20:20","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"The current DB for ecclesiastical archives in CH is originally stored in SQL; a conversion into excel is done and available (script for conversion from SQL into Excel also available)\r\nThe project has been started some years ago but did not progress due to several reasons. NOw the required data is available (approx. 1000 records). \r\nto be migrated into RDF / LOD format. repository is open; public shared folder on my Google drive (agga-db.xlsx). see below Source link to public Google drive.\r\ntechn...","hashtag":"","id":5,"ident":null,"image_url":"http://make.opendata.ch/wiki/project:kirchenarchive","is_challenge":true,"is_webembed":true,"logo_color":"","logo_icon":"","longtext":"The current DB for ecclesiastical archives in CH is originally stored in SQL; a conversion into excel is done and available (script for conversion from SQL into Excel also available)\r\nThe project has been started some years ago but did not progress due to several reasons. NOw the required data is available (approx. 1000 records). \r\nto be migrated into RDF / LOD format. repository is open; public shared folder on my Google drive (agga-db.xlsx). see below Source link to public Google drive.\r\ntechnical Assistance needed for reformatting and proposals for new output formats / presentation of the data are welcome.\r\npossibly a column should be added for PLZ Switzerland in order to create a map with the locations of the archives ....\r\n\r\n\r\n","maintainer":"jhagmann","name":"AGGA DB (VSA) - Kirchenarchive Schweiz","phase":"Challenge","progress":-1,"score":2,"source_url":"https://drive.google.com/open?id=1lo5iIYLAj7BCDhxuGyXGQr6AwPQ7dSOE","stats":{"commits":0,"during":0,"people":1,"sizepitch":736,"sizetotal":787,"total":2,"updates":0},"summary":"Create AGGA DB in RDF / LOD (conversion from Excel)","team":"jhagmann","team_count":1,"updated_at":"2020-05-24T20:20","url":"https://hack.glam.opendata.ch/project/5","webpage_url":"http://make.opendata.ch/wiki/project:kirchenarchive"},{"autotext":"","autotext_url":"https://www.dropbox.com/sh/19xssbc21gwve94/AADl0EKIagBXj3tVnD_OGKyTa?dl=0","category_id":"","category_name":"","contact_url":"christianlukas.stuber@students.bfh.ch","created_at":"2020-05-27T18:27","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"Explanations:\r\n\r\n- \u201cdepicts\u201d statements are used on Wikimedia Commons to describe the content of images by linking them to corresponding Wikidata items.\r\n\r\n- By a semi-automatic process, we mean the combination of machine-learning and crowdsourcing approaches in an attempt to maximize both accuracy and efficiency in order to allow for the \u201ctagging\u201d of large numbers of images in a relatively short time. \r\n\r\nWhat already has been done:\r\n\r\n- Three pretrained out-of-the-box object recognition servic...","hashtag":"","id":6,"ident":null,"image_url":"https://i.imgur.com/Zz1XqzK.png","is_challenge":true,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"Explanations:\r\n\r\n- \u201cdepicts\u201d statements are used on Wikimedia Commons to describe the content of images by linking them to corresponding Wikidata items.\r\n\r\n- By a semi-automatic process, we mean the combination of machine-learning and crowdsourcing approaches in an attempt to maximize both accuracy and efficiency in order to allow for the \u201ctagging\u201d of large numbers of images in a relatively short time. \r\n\r\nWhat already has been done:\r\n\r\n- Three pretrained out-of-the-box object recognition services (IBM Watson, Clarifai, Microsoft Azure) have been tested on photographs from a photo collection by Leo Wehrli and tested on a second collection. The best results were achieved through a combination of the three services, but the tagging is not reliable enough to allow for fully automatic processing. To facilitate double-checking of the tags by a human, an appropriate user interface should be created. Furthermore, the human feedback could be used to further train the algorithm. This is however not possible in the case of the three out-of-the box object recognition services. Instead, an algorithm should be trained from scratch. Eventually, human feedback could be gathered through a crowdsourcing approach and the algorithm be improved over time in order to maximize both the accuracy and efficiency of the tagging.\r\n\r\n- Most objects recognized by the three services have been successfully mapped to Wikidata items, and the metadata entries on Wikimedia Commons have been updated accordingly. The mapping between the objects recognized by the three services and Wikidata can partly be done automatically (for this, a python script on the basis of the SPARQL Endpoint was used); partly, the corresponding Wikidata items need to be looked up manually. For most objects there is a corresponding item on Wikidata; in very rare cases items on Wikidata need some cleanup. Some tags extracted by the services concern colors and not objects; they were not included in the data ingested on Wikimedia Commons. For the data ingest, the QuickStatements tool was used. A future app should allow users to write the verified data directly to Wikimedia Commons.\r\n\r\n- For further information what already has been done, see the presentation \"Does AI perform better? - Metadata Enhancement trough Deep Learning\", scheduled on 2 June 2020.\r\n\r\nWhat could be done during the hackathon:\r\n\r\n- Brainstorming what use cases would be of interest using the enriched linked data of such image collections (e.g. \"Show me all nature images in Bern 1900\")\r\n\r\n- Train a custom model. See \"instructions.pdf\" in \"Explore\") to generate the \"depicts\" statement of Wikimedia Commons.\r\n\r\n- Develop a prototype to show a practical application of the whole process (include crowdsourcing on the tasks where it is reasonable). See \"image_tagging_V04.py\" in \"Explore\" as example python script of how to get the tags from pretrained models with the embedded APIs of the used service.\r\n\r\nLink to video recording of the project presentation during the GLAMhack side programme: https://fhgr.webex.com/recordingservice/sites/fhgr/recording/playback/c3098c0cf14845ddb6f9338f400d4be7 (password: GLAMhack2020)\r\n","maintainer":"KriGoo","name":"Metadata Enhancement through Deep Learning","phase":"Challenge","progress":-1,"score":2,"source_url":"","stats":{"commits":0,"during":0,"people":3,"sizepitch":3168,"sizetotal":3265,"total":13,"updates":9},"summary":"Create an app to semi-automatically add \u201cdepicts\u201d statements to photographs on Wikimedia Commons.","team":"KriGoo, beatestermann, hhaider5","team_count":3,"updated_at":"2020-06-03T06:57","url":"https://hack.glam.opendata.ch/project/6","webpage_url":"https://www.dropbox.com/sh/19xssbc21gwve94/AADl0EKIagBXj3tVnD_OGKyTa?dl=0"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2020-06-04T16:35","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"Which level of detail should you choose when you define the genres of theatre events  - a shallow, in order to have a limited and fair amount to choose from, or a specific, with a lot of options, risking too much subjectivity in registering events? What would increase the possibilities for harmonising your data with other data models?","hashtag":"","id":13,"ident":null,"image_url":"","is_challenge":true,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"Which level of detail should you choose when you define the genres of theatre events  - a shallow, in order to have a limited and fair amount to choose from, or a specific, with a lot of options, risking too much subjectivity in registering events? What would increase the possibilities for harmonising your data with other data models?","maintainer":"niname","name":"Genre categories","phase":"Challenge","progress":-1,"score":2,"source_url":"https://ibsenstage.hf.uio.no/","stats":{"commits":0,"during":1,"people":2,"sizepitch":336,"sizetotal":421,"total":5,"updates":2},"summary":"Suggesting a discussion on how detailed you should be when defining genre categories. ","team":"niname, Kristin ","team_count":2,"updated_at":"2020-06-05T07:01","url":"https://hack.glam.opendata.ch/project/13","webpage_url":""},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2020-06-04T22:36","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"The Problem\r\n======\r\nMany domain experts are willing to manually contribute data, but have limited knowledge of data modelling best practices.  Although a domain expert has excellent domain knowledge, it is difficult to enter data accurately and consistently unless they have prior experience with the ontology. This excludes many potential contributors and sometimes leads to incompatible and unusable sets of data.\r\n\r\nThe Challenge\r\n===========\r\nThis challenge is to build a user interface to guide...","hashtag":"","id":15,"ident":null,"image_url":"","is_challenge":true,"is_webembed":true,"logo_color":"","logo_icon":"","longtext":"The Problem\r\n======\r\nMany domain experts are willing to manually contribute data, but have limited knowledge of data modelling best practices.  Although a domain expert has excellent domain knowledge, it is difficult to enter data accurately and consistently unless they have prior experience with the ontology. This excludes many potential contributors and sometimes leads to incompatible and unusable sets of data.\r\n\r\nThe Challenge\r\n===========\r\nThis challenge is to build a user interface to guide users when entering data, specifically around performing arts performances, productions and works. Ideally the fields to capture data are driven by [SHACL](http://datashapes.org/forms.html) shape definitions or a similar data based language. Questions guide the user to select the correct class and properties as they enter their data.  Options and suggestions are made as the user progresses.  Here is an [example of a friendly form](https://www.typeform.com/product/) with the ability to branch out based on answers to previous questions.\r\n\r\nSuccess\r\n======\r\n**The goal is reached** when 2 different people (without prior experience with the ontology) are given the same textual description (a group of related performances, productions and works) end up utilizing the data model in the same way and obtain the same results.","maintainer":"saumier","name":"Data Entry Wizard","phase":"Challenge","progress":-1,"score":2,"source_url":"","stats":{"commits":0,"during":0,"people":1,"sizepitch":1327,"sizetotal":1440,"total":2,"updates":0},"summary":"A data entry wizard with a friendly user interface to guide users in applying the correct classes and properties.","team":"saumier","team_count":1,"updated_at":"2020-06-04T22:36","url":"https://hack.glam.opendata.ch/project/15","webpage_url":"https://www.typeform.com/product/"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"https://glamhack2020.slack.com/archives/C0150GMJS20","created_at":"2020-06-04T15:12","download_url":"","event_name":"GLAMhack 2020","event_url":"https://hack.glam.opendata.ch/event/1","excerpt":"<h1>SFA data challenge</h1> \r\nAt the Swiss Federal Archives (SFA), we\u2019re looking for creative ways to improve access to our documents. Take up the SFA\u2019s data challenge! Write an app using our data search API and maybe we\u2019ll incorporate it into the Federal Archives\u2019 online access platform.\r\n\r\nOnline access, which went live at the end of 2019, enables millions of freely accessible data sets from the Federal Archives catalogue to be searched and \ufb01ltered using an API. You decide what the app does wi...","hashtag":"","id":12,"ident":null,"image_url":"https://www.bar.admin.ch/bar/en/home/research/searching/project-online-access/_jcr_content/par/image_1085373367/image.imagespooler.jpg/1589964220338/roadmap-challenge_flyer_EN.jpg","is_challenge":true,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"<h1>SFA data challenge</h1> \r\nAt the Swiss Federal Archives (SFA), we\u2019re looking for creative ways to improve access to our documents. Take up the SFA\u2019s data challenge! Write an app using our data search API and maybe we\u2019ll incorporate it into the Federal Archives\u2019 online access platform.\r\n\r\nOnline access, which went live at the end of 2019, enables millions of freely accessible data sets from the Federal Archives catalogue to be searched and \ufb01ltered using an API. You decide what the app does with the data: for example, you can develop a graphic search engine that links search results to metadata from other archives or libraries, or design a conversational agent. Two actual examples can be found under \"explore\". Help us improve access to the treasures of the Federal Archives!\r\n\r\n<h2>Our data</h2> \r\nThe Swiss Federal Archives hold documents from the Federal Administration, the Federal Assembly and the Federal Council, from foreign resident dossiers and parliamentary debates to customs treaties and trade agreements. In most cases, the online catalogue contains only brief metadata on the documents that are kept in our stacks: the title, reference code, creation period and accessibility under the Federal Act on Archiving (ArchA, SR 152.1). Some fonds are described in greater detail in the metadata: one example is the Schweizer Filmwochenschau, where transcripts of the spoken texts are also catalogued.\r\n\r\nThe search API accesses the catalogue\u2019s structured metadata. Documentation on the API can be found here: www.recherche.bar.admin.ch/recherche/#/en/information/api\r\n\r\nThe number of results per search request is limited to 10,000. For this reason, the app should be designed for a speci\ufb01c topic or for certain search functionalities rather than attempting to capture the data as a whole. \r\n\r\n<h2>Incentive</h2> \r\nThe participants in the most exciting projects (max. 25 people) will be invited to the Federal Archives. They will receive an exclusive guided tour of the archives and the opportunity to meet other challenge participants and staff of the Archives at a drinks reception. The date will be set as soon as it is clear that the restrictions associated with COVID-19 are going to be eased.\r\n\r\nSelected submissions will also be presented on our online channels. We may also contact individual developers or teams to integrate the functionalities into our offering. A payment will be made if this leads to a collaboration. \r\n\r\n<h2>More information</h2>\r\nView the complete <a href=\"https://www.bar.admin.ch/dam/bar/en/dokumente/diverses/roadmap-challenge_flyer_final_EN.pdf.download.pdf/roadmap-challenge_flyer_final_EN.pdf\">tender text</a>, join the <a href=\"https://glamhack2020.slack.com/archives/C0150GMJS20\">#project_sfa-data-challenge</a> on our Slack, or contact <a href=\"mailto:christa.ackermann@bar.admin.ch\">Christa Ackermann</a> for further information about the SFA Data Challenge.","maintainer":"SFA","name":"SFA Data Challenge","phase":"Challenge","progress":-1,"score":0,"source_url":"https://www.recherche.bar.admin.ch/recherche/#/en/information/api","stats":{"commits":0,"during":2,"people":1,"sizepitch":2919,"sizetotal":2992,"total":24,"updates":22},"summary":"Write an app using our data search API connecting to our online catalogue","team":"SFA","team_count":1,"updated_at":"2020-06-05T11:53","url":"https://hack.glam.opendata.ch/project/12","webpage_url":"https://www.bar.admin.ch/dam/bar/en/dokumente/diverses/roadmap-challenge_flyer_final_EN.pdf.download.pdf/roadmap-challenge_flyer_final_EN.pdf"}],"name":"projects"}],"sources":[{"path":"https://dribdat.cc","title":"dribdat"}],"title":"GLAMhack 2020","version":"0.2.0"}
